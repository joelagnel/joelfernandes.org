<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on JoelFernandes.org</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on JoelFernandes.org</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 25 Jun 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SVM and vectors for the curious</title>
      <link>http://localhost:1313/blog/2023/06/25/svm-and-vectors-for-the-curious/</link>
      <pubDate>Sun, 25 Jun 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/2023/06/25/svm-and-vectors-for-the-curious/</guid>
      <description>I posted a pair of articles/notes on SVM and vectors. I was curious how they worked and I&amp;rsquo;m sure these notes will be useful to me or others. Especially for some basic mathematics related to machine learning.&#xA;Notes on Vectors&#xA;Notes on SVM</description>
    </item>
    <item>
      <title>Dumping User and Kernel stacks on Kernel events</title>
      <link>http://localhost:1313/blog/2018/12/22/dumping-user-and-kernel-stacks-on-kernel-events/</link>
      <pubDate>Sat, 22 Dec 2018 20:28:24 -0500</pubDate>
      <guid>http://localhost:1313/blog/2018/12/22/dumping-user-and-kernel-stacks-on-kernel-events/</guid>
      <description>Dumping the native kernel and userspace stack when a certain path in the kernel or userspace occurs, can be useful to understand which code paths triggered a certain behavior that you&amp;rsquo;re trying to debug, such as an error you found in the log. One such case is when you notice Selinux denial messages in logs but want to know which path triggered it.&#xA;In this article we will show you how to use kernel instrumentation and BCC to dump the both the user and kernel stack.</description>
    </item>
    <item>
      <title>USDT for reliable Userspace event tracing</title>
      <link>http://localhost:1313/blog/2018/02/10/usdt-for-reliable-userspace-event-tracing/</link>
      <pubDate>Sat, 10 Feb 2018 23:22:39 -0800</pubDate>
      <guid>http://localhost:1313/blog/2018/02/10/usdt-for-reliable-userspace-event-tracing/</guid>
      <description>Userspace program when compiled to native can place tracepoints in them using a USDT (User Statically Defined Tracing), the details of the tracepoints (such as address and arguments) are placed as a note in the ELF binary for other tools to interpret. This at first seems much better than using Uprobes directly on userspace functions, since the latter not only needs symbol information from the binary but is also at the mercy of compiler optimizations and function inlining.</description>
    </item>
    <item>
      <title>ARMv8: flamegraph and NMI support</title>
      <link>http://localhost:1313/blog/2016/12/31/armv8-flamegraph-and-nmi-support/</link>
      <pubDate>Sat, 31 Dec 2016 22:29:26 -0700</pubDate>
      <guid>http://localhost:1313/blog/2016/12/31/armv8-flamegraph-and-nmi-support/</guid>
      <description>Non-maskable interrupts (NMI) is a really useful feature for debugging, that hardware can provide. Unfortunately ARM doesn&amp;rsquo;t provide an out-of-the-box NMI interrupt mechanism. This post shows a flamegraph issue due to missing NMI support, and the upstream work being done to simulate NMI in ARMv8.&#xA;Some great Linux kernel features that rely on NMI to work properly are:&#xA;Backtrace from all CPUs: A number of places in the kernel rely on dumping the stacks of all CPUs at the time of a failure to determine what was going on.</description>
    </item>
    <item>
      <title>Ftrace events mechanism</title>
      <link>http://localhost:1313/blog/2016/06/18/ftrace-events-mechanism/</link>
      <pubDate>Sat, 18 Jun 2016 22:29:26 -0700</pubDate>
      <guid>http://localhost:1313/blog/2016/06/18/ftrace-events-mechanism/</guid>
      <description>Ftrace events are a mechanism that allows different pieces of code in the kernel to &amp;lsquo;broadcast&amp;rsquo; events of interest. Such as a scheduler context-switch sched_switch for example. In the scheduler core&amp;rsquo;s __schedule function, you&amp;rsquo;ll see something like: trace_sched_switch(preempt, prev, next); This immediately results in a write to a per-cpu ring buffer storing info about what the previous task was, what the next one is, and whether the switch is happening as a result of kernel preemption (versus happening for other reasons such as a task waiting for I/O completion).</description>
    </item>
    <item>
      <title>TIF_NEED_RESCHED: why is it needed</title>
      <link>http://localhost:1313/blog/2016/03/20/tif_need_resched-why-is-it-needed/</link>
      <pubDate>Sun, 20 Mar 2016 01:44:32 -0700</pubDate>
      <guid>http://localhost:1313/blog/2016/03/20/tif_need_resched-why-is-it-needed/</guid>
      <description>TIF_NEED_RESCHED is one of the many &amp;ldquo;thread information flags&amp;rdquo; stored along side every task in the Linux Kernel. One of the flags which is vital to the working of preemption is TIF_NEED_RESCHED. Inorder to explain why its important and how it works, I will go over 2 cases where TIF_NEED_RESCHED is used.&#xA;Preemption Preemption is the process of forceably grabbing CPU from a user or kernel context and giving it to someone else (user or kernel).</description>
    </item>
    <item>
      <title>Tying 2 voltage sources/signals together</title>
      <link>http://localhost:1313/blog/2015/12/25/tying-2-voltage-sources/signals-together/</link>
      <pubDate>Fri, 25 Dec 2015 14:51:29 -0600</pubDate>
      <guid>http://localhost:1313/blog/2015/12/25/tying-2-voltage-sources/signals-together/</guid>
      <description>Recently I asked a question on StackExchange about what happens when 2 voltage signals are tied together. What&amp;rsquo;s the resultant voltage and what decides this voltage? The whole train of thought started when I was trying to contemplate what happens when you use pull-ups on signals that are not Open Drain.&#xA;I create and simulated a Circuit with the same scenario in LTSpice. &amp;ldquo;V&amp;rdquo; is the voltage between the &amp;ldquo;+&amp;rdquo; terminals of V1 and V2 and its shown on the right of the simulation.</description>
    </item>
    <item>
      <title>MicroSD card remote switch</title>
      <link>http://localhost:1313/blog/2014/06/04/microsd-card-remote-switch/</link>
      <pubDate>Wed, 04 Jun 2014 06:12:55 -0500</pubDate>
      <guid>http://localhost:1313/blog/2014/06/04/microsd-card-remote-switch/</guid>
      <description>Recently, I&amp;rsquo;ve been wanting to remotely be able to program a MicroSD card with a new bootloader or filesystem without removing the card from its embedded target board (such as a Beaglebone or Pandaboard). Due to the lack of any such existing tools, I decided to design my own board. Finally have got it working, below are some pictures and a screencast demo video of the switcher in action! I sprinkled some power and status LED to show the user what&amp;rsquo;s going on.</description>
    </item>
    <item>
      <title>Linux Spinlock Internals</title>
      <link>http://localhost:1313/blog/2014/05/07/linux-spinlock-internals/</link>
      <pubDate>Wed, 07 May 2014 22:42:45 -0500</pubDate>
      <guid>http://localhost:1313/blog/2014/05/07/linux-spinlock-internals/</guid>
      <description>This article tries to clarify how spinlocks are implemented in the Linux kernel and how they should be used correctly in the face of preemption and interrupts. The focus of this article will be more on basic concepts than details, as details tend to be forgotten more easily and shouldn&amp;rsquo;t be too hard to look up although attention is paid to it to the extent that it helps understanding.&#xA;Fundamentally somewhere in include/linux/spinlock.</description>
    </item>
    <item>
      <title>Studying cache-line sharing effects on SMP systems</title>
      <link>http://localhost:1313/blog/2014/04/24/studying-cache-line-sharing-effects-on-smp-systems/</link>
      <pubDate>Thu, 24 Apr 2014 20:28:24 -0500</pubDate>
      <guid>http://localhost:1313/blog/2014/04/24/studying-cache-line-sharing-effects-on-smp-systems/</guid>
      <description>Having read the chapter on counting and per-CPU counters in Paul Mckenney&amp;rsquo;s recent book, I thought I would do a small experiment to check how good or bad it would be if those per-CPU counters were close to each other in memory.&#xA;Paul talks about using one global shared counter for N threads on N CPUs, and the effects it can have on the cache. Each CPU core&amp;rsquo;s cache in an SMP system will need exclusive rights on a specific cache line of memory, before it can do the write.</description>
    </item>
    <item>
      <title>Design of fork followed by exec in Linux</title>
      <link>http://localhost:1313/blog/2014/04/22/design-of-fork-followed-by-exec-in-linux/</link>
      <pubDate>Tue, 22 Apr 2014 23:06:11 -0500</pubDate>
      <guid>http://localhost:1313/blog/2014/04/22/design-of-fork-followed-by-exec-in-linux/</guid>
      <description>A lot of folks ask why do you have to do fork and then an exec, to execute a new program? and why can&amp;rsquo;t it be done in one step?, or why does fork create a copy-on-writed address space, to only have it thrown away later when you do an exec?. So I decided do a small write up about this topic.&#xA;On a separate note, firstly it is important to remember that fork is not used for threading, its primary use is to create a separate process, that is a child of the parent process that called fork.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/blog/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/</guid>
      <description>“Two roads diverged in a wood, and I took the one less traveled by, And that has made all the difference” &amp;ndash; The Spirit Of Frost </description>
    </item>
    <item>
      <title>BPFd- Running BCC tools remotely across systems</title>
      <link>http://localhost:1313/blog/1/01/01/bpfd-running-bcc-tools-remotely-across-systems/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/bpfd-running-bcc-tools-remotely-across-systems/</guid>
      <description>This article (with some edits) also appeared on LWN.&#xA;Introduction BCC (BPF Compiler Collection) is a toolkit and a suite of kernel tracing tools that allow systems engineers to efficiently and safely get a deep understanding into the inner workings of a Linux system. Because they can&amp;rsquo;t crash the kernel, they are safer than kernel modules and can be run in production environments. Brendan Gregg has written nice tools and given talks showing the full power of eBPF based tools.</description>
    </item>
    <item>
      <title>C&#43;&#43; rvalue references</title>
      <link>http://localhost:1313/blog/1/01/01/c-rvalue-references/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/c-rvalue-references/</guid>
      <description>The author works in the ChromeOS kernel team, where most of the system libraries, low-level components and user space is written in C++. Thus the writer has no choice but to be familiar with C++. It is not that hard, but some things are confusing. rvalue references are definitely confusing.&#xA;In this post, I wish to document rvalue references by simple examples, before I forget it.&#xA;Refer to this article for in-depth coverage on rvalue references.</description>
    </item>
    <item>
      <title>Figuring out herd7 memory models</title>
      <link>http://localhost:1313/blog/1/01/01/figuring-out-herd7-memory-models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/figuring-out-herd7-memory-models/</guid>
      <description>This article has been published as a PDF, download here.</description>
    </item>
    <item>
      <title>Getting YouCompleteMe working for kernel development</title>
      <link>http://localhost:1313/blog/1/01/01/getting-youcompleteme-working-for-kernel-development/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/getting-youcompleteme-working-for-kernel-development/</guid>
      <description>YCM is a pretty neat tool for speedy kernel development in vim. Especially when you don&amp;rsquo;t want to write a whole bunch of code, and then deal with 100s of compiler errors. It is better to fix the errors on the spot, as you write the code. That&amp;rsquo;s exactly what YCM is best at since it constantly builds the code on the fly. The other great thing about it among other things being, it will show you function prototypes and so forth as you type, so you can call functions correctly with the right set of parameters and types.</description>
    </item>
    <item>
      <title>GUS (Global Unbounded Sequences)</title>
      <link>http://localhost:1313/blog/1/01/01/gus-global-unbounded-sequences/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/gus-global-unbounded-sequences/</guid>
      <description>GUS is a memory reclaim algorithm used in FreeBSD, similar to RCU. It is borrows concepts from Epoch and Parsec. A video of a presentation describing the integration of GUS with UMA (FreeBSD&amp;rsquo;s slab implementation) is here: https://www.youtube.com/watch?v=ZXUIFj4nRjk&#xA;The best description of GUS is in the FreeBSD code itself. It is based on the concept of global write clock, with readers catching up to writers.&#xA;Effectively, I see GUS as an implementation of light traveling from distant stars.</description>
    </item>
    <item>
      <title>Making sense of scheduler deadlocks in RCU</title>
      <link>http://localhost:1313/blog/1/01/01/making-sense-of-scheduler-deadlocks-in-rcu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/making-sense-of-scheduler-deadlocks-in-rcu/</guid>
      <description>Note: At the time of this writing, it is kernel v5.3 release. RCU moves fast and can change in the future, so some details in this article may be obsolete.&#xA;The RCU subsystem and the task scheduler are inter-dependent. They both depend on each other to function correctly. The scheduler has many data structures that are protected by RCU. And, RCU may need to wake up threads to perform things like completing grace periods and callback execution.</description>
    </item>
    <item>
      <title>Modeling (lack of) store ordering using PlusCal - and a wishlist</title>
      <link>http://localhost:1313/blog/1/01/01/modeling-lack-of-store-ordering-using-pluscal-and-a-wishlist/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/modeling-lack-of-store-ordering-using-pluscal-and-a-wishlist/</guid>
      <description>The Message Passing pattern (MP pattern) is shown in the snippet below (borrowed from LKMM docs). Here, P0 and P1 are 2 CPUs executing some code. P0 stores a message in buf and then signals to consumers like P1 that the message is available &amp;ndash; by doing a store to flag. P1 reads flag and if it is set, knows that some data is available in buf and goes ahead and reads it.</description>
    </item>
    <item>
      <title>On workings of hrtimer&#39;s slack time functionality</title>
      <link>http://localhost:1313/blog/1/01/01/on-workings-of-hrtimers-slack-time-functionality/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/on-workings-of-hrtimers-slack-time-functionality/</guid>
      <description>Below are some notes I wrote while studying hrtimer slack behavior (range timers), which was added to reduce wakeups and save power, in the commit below. The idea is that:&#xA;Normal hrtimers will have both a soft and hard expiry which are equal to each other. But hrtimers with timer slack will have a soft expiry and a hard expiry which is the soft expiry + delta. The slack/delay effect is achieved by splitting the execution of the timer function, and the programming of the next timer event into 2 separate steps.</description>
    </item>
    <item>
      <title>PowerPC stack guard false positives in Linux kernel</title>
      <link>http://localhost:1313/blog/1/01/01/powerpc-stack-guard-false-positives-in-linux-kernel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/powerpc-stack-guard-false-positives-in-linux-kernel/</guid>
      <description>Recently, the RCU mailing list received a report about an SRCU function failing stack guard checks.&#xA;Stack guard canaries are a security mechanism used to detect stack buffer overflows. This mechanism works by placing a random value, called a canary, between the local variables and the return address on the stack. If a buffer overflow occurs, the canary value will be overwritten and the stack guard check will fail, indicating that the program is being attacked.</description>
    </item>
    <item>
      <title>RCU and dynticks-idle mode</title>
      <link>http://localhost:1313/blog/1/01/01/rcu-and-dynticks-idle-mode/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/rcu-and-dynticks-idle-mode/</guid>
      <description>Note 1: RCU is an extremely complex topic and I make no claims of accuracy, correctness and don&amp;rsquo;t make any claims that this document is to be used as a defacto reference for any purpose. You have been warned! For more accurate and standard references, I will refer you to the kernel RCU documentation. Please consider this post as rough notes. That said, your corrections, and comments are welcomed.&#xA;Note 2: The article is a WIP and not fully finished (thought it is almost).</description>
    </item>
    <item>
      <title>RCU-preempt: What happens on a context switch</title>
      <link>http://localhost:1313/blog/1/01/01/rcu-preempt-what-happens-on-a-context-switch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/rcu-preempt-what-happens-on-a-context-switch/</guid>
      <description>Note: This article requires knowledge of RCU (read copy update) basics and its different flavors.&#xA;RCU&amp;rsquo;s main algorithm is to detect when it is free to reclaim objects that RCU readers no longer need. The &amp;ldquo;RCU-sched&amp;rdquo; flavor of RCU does this by just disabling preemption across the read section. So any time any of the CPUs is not running in a preempt disabled section (such as with preemption off, or interrupts off), then the CPU is said to be in a &amp;ldquo;quiescent state&amp;rdquo; (QS).</description>
    </item>
    <item>
      <title>SELinux Debugging on ChromeOS</title>
      <link>http://localhost:1313/blog/1/01/01/selinux-debugging-on-chromeos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/selinux-debugging-on-chromeos/</guid>
      <description>Not being an SELinux expert but having to deal with it from time-to-time, I find it may be productive to write some debugging notes. So this post is about an issue that I fixed just this morning.&#xA;Issue: Runtime labeled pseudo-files are not getting labelled On ChromeOS, there are Android-specific policies which are combined with the ChromeOS ones. For someone who tries to stay away from SELinux, this is pretty much voodoo.</description>
    </item>
    <item>
      <title>Single-stepping the kernel&#39;s C code</title>
      <link>http://localhost:1313/blog/1/01/01/single-stepping-the-kernels-c-code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/single-stepping-the-kernels-c-code/</guid>
      <description>Recently, I have had to use the GNU debugger (gdb) connected to a Qemu instance of a RISC-V processor to step through some kernel code.&#xA;Turns out that the Linux kernel is compiled with gcc -O2 flag for optimizations it needs during the build. This causes several problems for a debugger. One of them is that the gdb command info registers will show values as &amp;lt;optimized out&amp;gt;. Another issue is that single-stepping will make the debugger appear to jump back and forth across lines of code as code is stepped through with next or step gdb commands.</description>
    </item>
    <item>
      <title>SRCU state double scan</title>
      <link>http://localhost:1313/blog/1/01/01/srcu-state-double-scan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/srcu-state-double-scan/</guid>
      <description>The SRCU flavor of RCU uses per-cpu counters to detect that every CPU has passed through a quiescent state for a particular SRCU lock instance (srcu_struct).&#xA;There&amp;rsquo;s are total of 4 counters per-cpu. One pair for locks, and another for unlocks. You can think of the SRCU instance to be split into 2 parts. The readers sample srcu_idx and decided which part to use. Each part corresponds to one pair of lock and unlock counters.</description>
    </item>
    <item>
      <title>Understanding Hazard Pointers</title>
      <link>http://localhost:1313/blog/1/01/01/understanding-hazard-pointers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/understanding-hazard-pointers/</guid>
      <description>Introduction In concurrent systems, managing shared resources efficiently and safely is of paramount importance. Hazard pointers are a powerful synchronization mechanism that can be used to address this issue. In this post, we will explore how hazard pointers work, provide a simple example to illustrate their usage, and compare them with RCU (Read-Copy-Update). Additionally, we will dive into the implementation details of hazard pointers, including the per-CPU and per-thread data structures used to maintain them.</description>
    </item>
  </channel>
</rss>
