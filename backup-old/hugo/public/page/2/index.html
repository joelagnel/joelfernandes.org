<!DOCTYPE html>


<html class="no-js" lang="en">
<head>
	<meta name="generator" content="Hugo 0.123.7"><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
  <title>JoelFernandes.org - JoelFernandes.org</title>
  <meta name="author" content="Joel Fernandes">

  
  <meta name="description" content="">

  
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="canonical" href="http://localhost:1313/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="\/javascripts\/libs\/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  
  
</head>
<body   >
  <header role="banner"><div>
<div style="margin-right:50px;float:left;">
  <h1><a href="/">JoelFernandes.org</a></h1>
  
</div>
<div style="float:left;" class="hnav">
 <br>
 
 <a href="/categories/">Blog posts by category.</a><br>
 <a href="/blog/archives/">Archive of all blog posts.</a><br>
 <a href="/resources/">Presentations and other work.</a><br>
</div>
<div style="float:right;">
<img src="/images/peng.png" height=100 width=100>
</div>
</div></header>

  <div id="main">
    <div id="content">
      
<div class="blog-index">

<article>
Hello! I'm Joel and this my personal website built with Hugo! I currently
work at Google. My interests are scheduler, RCU, tracing, synchronization,
memory models and other kernel internals. I also love contributing to the
upstream Linux kernel and other open source projects.

Connect with me on [Twitter](https://twitter.com/joel_linux), and
[LinkedIn](https://www.linkedin.com/in/joelagnel). Or, drop me an email at:
joel _at_ joelfernandes _dot_ org

Look for my name in the kernel git log to find my upstream kernel patches.
Check out [my resume](/joel/joel-resume.pdf) for full details of my work
experience. I also actively present at conferences, see a list of my past
[talks, presentations and publications](/resources).

Full list of all blog posts on this site:

<font face="monospace">
 <li>
   <span>25 Jun 2023</span> &nbsp; <a href="http://localhost:1313/blog/2023/06/25/svm-and-vectors-for-the-curious/">SVM and vectors for the curious</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>22 Dec 2018</span> &nbsp; <a href="http://localhost:1313/blog/2018/12/22/dumping-user-and-kernel-stacks-on-kernel-events/">Dumping User and Kernel stacks on Kernel events</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>10 Feb 2018</span> &nbsp; <a href="http://localhost:1313/blog/2018/02/10/usdt-for-reliable-userspace-event-tracing/">USDT for reliable Userspace event tracing</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>31 Dec 2016</span> &nbsp; <a href="http://localhost:1313/blog/2016/12/31/armv8-flamegraph-and-nmi-support/">ARMv8: flamegraph and NMI support</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>18 Jun 2016</span> &nbsp; <a href="http://localhost:1313/blog/2016/06/18/ftrace-events-mechanism/">Ftrace events mechanism</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>20 Mar 2016</span> &nbsp; <a href="http://localhost:1313/blog/2016/03/20/tif_need_resched-why-is-it-needed/">TIF_NEED_RESCHED: why is it needed</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>25 Dec 2015</span> &nbsp; <a href="http://localhost:1313/blog/2015/12/25/tying-2-voltage-sources/signals-together/">Tying 2 voltage sources/signals together</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>04 Jun 2014</span> &nbsp; <a href="http://localhost:1313/blog/2014/06/04/microsd-card-remote-switch/">MicroSD card remote switch</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>07 May 2014</span> &nbsp; <a href="http://localhost:1313/blog/2014/05/07/linux-spinlock-internals/">Linux Spinlock Internals</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>24 Apr 2014</span> &nbsp; <a href="http://localhost:1313/blog/2014/04/24/studying-cache-line-sharing-effects-on-smp-systems/">Studying cache-line sharing effects on SMP systems</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>22 Apr 2014</span> &nbsp; <a href="http://localhost:1313/blog/2014/04/22/design-of-fork-followed-by-exec-in-linux/">Design of fork followed by exec in Linux</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/"></a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/bpfd-running-bcc-tools-remotely-across-systems/">BPFd- Running BCC tools remotely across systems</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/c-rvalue-references/">C&#43;&#43; rvalue references</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/categories/">Categories</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/joel/">false</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/figuring-out-herd7-memory-models/">Figuring out herd7 memory models</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/getting-youcompleteme-working-for-kernel-development/">Getting YouCompleteMe working for kernel development</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/gus-global-unbounded-sequences/">GUS (Global Unbounded Sequences)</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/archives/">List of articles</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/making-sense-of-scheduler-deadlocks-in-rcu/">Making sense of scheduler deadlocks in RCU</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/modeling-lack-of-store-ordering-using-pluscal-and-a-wishlist/">Modeling (lack of) store ordering using PlusCal - and a wishlist</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/on-workings-of-hrtimers-slack-time-functionality/">On workings of hrtimer&#39;s slack time functionality</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/powerpc-stack-guard-false-positives-in-linux-kernel/">PowerPC stack guard false positives in Linux kernel</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/rcu-and-dynticks-idle-mode/">RCU and dynticks-idle mode</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/rcu-preempt-what-happens-on-a-context-switch/">RCU-preempt: What happens on a context switch</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/resources/">Resources</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/selinux-debugging-on-chromeos/">SELinux Debugging on ChromeOS</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/single-stepping-the-kernels-c-code/">Single-stepping the kernel&#39;s C code</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/srcu-state-double-scan/">SRCU state double scan</a> 
 </li>
</font>

<font face="monospace">
 <li>
   <span>01 Jan 0001</span> &nbsp; <a href="http://localhost:1313/blog/1/01/01/understanding-hazard-pointers/">Understanding Hazard Pointers</a> 
 </li>
</font>

</article>


 


    <article>
Most Recent Post:
      
  <header>
    
      <h1 class="entry-title">Design of fork followed by exec in Linux</h1>
    
    
      <p class="meta">
        
<time datetime="2014-04-22T23:06:11-05:00" pubdate data-updated="true">Apr 22, 2014</time>

        
           | <a href="http://localhost:1313/blog/2014/04/22/design-of-fork-followed-by-exec-in-linux/#disqus_thread"
             data-disqus-identifier="http://localhost:1313/blog/2014/04/22/design-of-fork-followed-by-exec-in-linux/">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>A lot of folks ask <em>why do you have to do fork and then an exec, to execute a new program?</em> and <em>why can&rsquo;t it be done in one step?</em>, or <em>why does fork <a href="http://man7.org/linux/man-pages/man2/fork.2.html">create a copy-on-writed address space</a>, to only have it thrown away later when you do an exec?</em>. So I decided do a small write up about this topic.</p>
<p>On a separate note, firstly it is important to remember that <code>fork</code> is not used for threading, its primary use is to create a separate process, that is a child of the parent process that called <code>fork</code>.</p>
<p>Normally one might think that doing a <code>fork</code> and separate <code>exec</code> can be combined in one step, and it probably should be. But there are applications of maintaining this separation. Here&rsquo;s a <a href="http://stackoverflow.com/questions/1345320/applications-of-fork-system-call">post that explains</a> why you might need to do just a <code>fork</code> call. Summarizing the post, you may need to setup some initial data and &ldquo;fork&rdquo; a bunch of workers. All these works are supposed to execute in <em>their own</em> address space and share <em>only the initial data</em>. In this case, copy-on-write is extremely useful since the initial data can be shared in physical memory and forking this way would be extremely cheap. The kernel marks all these shared pages as read only, and makes writable copies of shared data when they are written to.</p>
<p>There is a small overhead if <code>fork</code> is followed immediately by an <code>exec</code> system call, since the copy-on-write shared address space is of no use and is thrown away anyway. Combining both the <code>fork</code>, <code>exec</code> in this case might might have some advantages, reducing this overhead.</p>
<h2 id="linux-implementation-of-copy-on-write-cow-for-shared-virtual-memory-areas">Linux Implementation of Copy-on-write (COW) for shared Virtual Memory Areas</h2>
<p>Some of this COW code that executes on a fork can be found in <code>mm/memory.c</code>. There is an is_cow function to detect if a virtual memory area (a region of virtual memory, see <code>/proc/self/maps</code>) is copy-on-write.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#66d9ef">static</span> <span style="color:#66d9ef">inline</span> <span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">is_cow_mapping</span>(<span style="color:#66d9ef">vm_flags_t</span> flags)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> (flags <span style="color:#f92672">&amp;</span> (VM_SHARED <span style="color:#f92672">|</span> VM_MAYWRITE)) <span style="color:#f92672">==</span> VM_MAYWRITE;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>A VMA (Virtual Memory Area) is a contiguous segment of virtual memory belonging to a particular process. Every VMA has a bunch of VM_ flags associated with it. <code>VM_MAYWRITE</code>, relevant to the above code, is used to mark that a mapped region can be changed to writable by mprotect system call. It is possible that a memory region is initially readonly and the user wants to make it writable. <code>VM_MAYWRITE</code> gives that permission. Note that if if the kernel doesn&rsquo;t set <code>VM_MAYWRITE</code>, then the region is automatically not COW because there is no question of writing to it.</p>
<p>When a memory mapping is created via the mmap system call, and if <code>MAP_SHARED</code> is passed in flags, the <code>VM_SHARED</code> bit is set for the VMA and as a result the region is not copy-on-write (The above is_cow_mapping function returns false). By definition, shared memory regions are just that - shared. So no need copy-on-write. In other words, If the VMA is a shared mapping or is a read only mapping, then it isn&rsquo;t a COW mapping.</p>
<p>Let&rsquo;s take the example of mapping a file using mmap,</p>
<p>By default in the kernel on VMA creation, the VMA flags is set to <code>VM_SHARED = 0</code> and <code>VM_MAYWRITE = 1</code>. Now if mmap is asked it to create a shared mapping of a file by passing it <code>MAP_SHARED</code> flag, for example, that can be shared with other processes that are being forked, then the <code>VM_SHARED</code> bit is set to 1 for that VMA. Additionally if the file is opened in read only mode, then <code>VM_MAYWRITE</code> is set to 1. This has the effect of making is_cow_mapping return false. Ofcourse, the shared mapping doesn&rsquo;t need to be a COW.</p>
<p>On the other hand, if <code>MAP_PRIVATE</code> is passed in the flags to mmap, then <code>VM_SHARED</code> bit is set to 0, and <code>VM_MAYWRITE</code> remains at 1 (regardless of whether the file is read or write opened, since writes will not be carried to the underlying file). This makes is_cow_mapping return true. Indeed, private mappings should be copy-on-write enabled.</p>
<p>You can see the code I&rsquo;m talking about <a href="http://lxr.free-electrons.com/source/mm/mmap.c#L1284">conveniently here</a>.</p>
<p>The important point here is that every mapping is either a COW mapping or not a COW mapping. During the <code>clone</code> system call which is called by <code>fork</code> library call internally, if the <code>CLONE_VM</code> flag is not passed to <code>clone</code> as is the case internally within <code>fork</code>, then all the VMA mappings of the parent process are copied to the child, including the page table entries. In this case, any writes to COW mappings should trigger a copy on write. The main thing to note is the children <em>inherit</em> the COW property of all the copied VMA mappings of its parent and don&rsquo;t need to be explictly marked as COW.</p>
<p>However, If <code>CLONE_VM</code> is passed, then the VMAs are not copied and the memory descriptor of the child and the parent process are the same, in this case the child and parent share the same address space and are thus are threads. <a href="http://lxr.free-electrons.com/source/kernel/fork.c#L879">See for yourself</a>. COW or no COW doesn&rsquo;t matter here.</p>
<p>So here&rsquo;s a question for you, For N <code>clone</code> system calls with <code>!CLONE_VM</code> passed for spawning N threads, we can just create as many VMA copies as we want each time, the COW mappings will take care of themselves. Right? Almost! There&rsquo;s more work&hellip; the <em>physical pages</em> of both the original VMA and the copy VMA have to be marked as read-only. That&rsquo;s the only way Copy-on-write of those will be triggered by the CPU when those pages are written to. Here&rsquo;s the code in <a href="http://lxr.free-electrons.com/source/mm/memory.c#L849">copy_one_pte</a> that sets this up:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>         <span style="color:#75715e">/*
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">          * If it&#39;s a COW mapping, write protect it both
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">          * in the parent and the child
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">          */</span>
</span></span><span style="display:flex;"><span>         <span style="color:#66d9ef">if</span> (<span style="color:#a6e22e">is_cow_mapping</span>(vm_flags)) {
</span></span><span style="display:flex;"><span>                 <span style="color:#a6e22e">ptep_set_wrprotect</span>(src_mm, addr, src_pte);
</span></span><span style="display:flex;"><span>                 pte <span style="color:#f92672">=</span> <span style="color:#a6e22e">pte_wrprotect</span>(pte);
</span></span><span style="display:flex;"><span>         }
</span></span></code></pre></div><p>There you go, now when the COW memory region is written to, a page fault happens, and the page fault handler knows that the VMA of the faulting page is a COW and that&rsquo;s what triggered the page fault. It can then create a copy of the page and restart the faulting instruction, this time removing the write protection if there aren&rsquo;t any others sharing the VMA. So in short, fork+exec can be expensive if you had done lots of <code>fork</code> calls on a process with a lot of large files. Since all this copying business is wasted on doing a subsequent <code>exec</code> system call.</p>
<p>There is one optimization however, why should you have to do this marking for pages that are not physically present in memory? Those will fault anyway. So the above code is <em>not run</em> if the page is not present, nicely done by checking for <code>!pte_present(pte)</code> to be true before the preceding code.</p>
<p>Please share any comments you may have in the comments section.</p>
</div>

    </article>

    <article>
Most Recent Post:
      
  <header>
    
      <h1 class="entry-title"></h1>
    
    
      <p class="meta">
        
        
           | <a href="http://localhost:1313/blog/1/01/01/#disqus_thread"
             data-disqus-identifier="http://localhost:1313/blog/1/01/01/">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>“Two roads diverged in a wood, and I took the one less traveled by, And that has made all the difference” &ndash; The Spirit Of Frost </p>
</div>

    </article>

    <article>
Most Recent Post:
      
  <header>
    
      <h1 class="entry-title">BPFd- Running BCC tools remotely across systems</h1>
    
    
      <p class="meta">
        
        
           | <a href="http://localhost:1313/blog/1/01/01/bpfd-running-bcc-tools-remotely-across-systems/#disqus_thread"
             data-disqus-identifier="http://localhost:1313/blog/1/01/01/bpfd-running-bcc-tools-remotely-across-systems/">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>This article (with some edits) also <a href="https://lwn.net/Articles/744522/">appeared on LWN</a>.</p>
<h2 id="introduction">Introduction</h2>
<p><a href="https://github.com/iovisor/bcc/blob/master/README.md">BCC (BPF Compiler Collection)</a> is a toolkit and a suite of kernel
tracing tools that allow systems engineers to efficiently and safely get a deep understanding into the inner workings of
a Linux system. Because they can&rsquo;t crash the kernel, they are safer than kernel modules and can be run in production
environments. <a href="http://www.brendangregg.com/ebpf.html">Brendan Gregg has written</a> nice tools and given talks showing the
full power of eBPF based tools. Unfortunately, BCC has no support for a cross-development workflow. I define
&ldquo;cross-development&rdquo; as a development workflow in which the development machine and the target machine running the
developed code are different. Cross-development is very typical among Embedded System kernel developers who often
develop on a powerful x86 host and then flash and test their code on SoCs (System on Chips) based on the ARM
architecture. Not having a cross-development flow gives rise to several complications, lets go over them and discuss a
solution called BPFd that cleverly addresses this issue.</p>
<p>In the Android kernel team, we work mostly on ARM64 systems, since most Android devices are on this architecture. BCC
tools support on ARM64 systems has stayed broken for years. One of the reasons for this difficulty is with ARM64 inline
assembler statements. Unavoidably, kernel header includes in BCC tools result in inclusion of asm headers which in the
case of ARM64 has the potential of spewing inline asm ARM64 instructions <a href="https://www.mail-archive.com/iovisor-dev@lists.iovisor.org/msg00299.html">causing major
pains</a>  to LLVM&rsquo;s BPF backend. Recently this
issue got fixed by BPF inline asm support (these
<a href="https://github.com/llvm-mirror/llvm/commit/2865ab6996164e7854d55c9e21c065fad7c26569">LLVM</a> <a href="https://github.com/llvm-mirror/llvm/commit/a6b7d22c2e64f44e6c74ad7e5ce5670f5ae72da3">commits</a>) and <a href="(https://github.com/iovisor/bcc/issues/1202)">folks could finally run BCC
tools on arm64</a>, but..</p>
<p>In order for BCC tools to work at all, they need kernel sources. This is because most tools need to register callbacks
on the ever-changing kernel API in order to get their data. Such callbacks are registered using the
<a href="https://lwn.net/Articles/132196/">kprobe</a> infrastructure. When a BCC tool is run, BCC switches its current directory
into the kernel source directory before compilation starts, and compiles the C program that embodies the BCC tool&rsquo;s
logic. The C program is free to include kernel headers for <code>kprobes</code> to work and to use kernel data structures.</p>
<p>Even if one were not to use <code>kprobes</code>, BCC also implicity adds a common <code>helpers.h</code> include directive  whenever an eBPF
C program is being compiled, found in <code>src/cc/export/helpers.h</code> in the BCC sources. This <code>helpers.h</code> header uses the
<code>LINUX_VERSION_CODE</code> macro to create a &ldquo;version&rdquo; section in the compiled output. <code>LINUX_VERSION_CODE</code> is available only
in the specific kernel&rsquo;s sources being targeted and is used during eBPF program loading to make sure the BPF program is
being loaded into a kernel with the right version. As you can see, kernel sources quickly become mandatory for compiling
eBPF programs.</p>
<p>In some sense this build process is similar to how external kernel modules are built. Kernel sources are large in size
and often can take up a large amount of space on the system being debugged. They can also get out of sync, which may
make the tools misbehave.</p>
<p>The other issue is Clang and LLVM libraries need to be available on the target being traced. This is because the tools
compile the needed BPF bytecode which are then loaded into the kernel. These libraries take up a lot space. It seems
overkill that you need a full-blown compiler infrastructure on a system when the BPF code can be compiled elsewhere and
maybe even compiled just once. Further, these libraries need to be cross-compiled to run on the architecture you&rsquo;re
tracing. That&rsquo;s possible, but why would anyone want to do that if they didn&rsquo;t need to? Cross-compiling compiler
toolchains can be tedious and stressful.</p>
<h2 id="bpfd-a-daemon-for-running-ebpf-bcc-tools-across-systems">BPFd: A daemon for running eBPF BCC tools across systems</h2>
<p><a href="https://github.com/joelagnel/bpfd">Sources for BPFd can be downloaded here</a>.</p>
<p>Instead of loading up all the tools, compiler infrastructure and kernel sources onto the remote targets being traced and
running BCC that way, I decided to write a proxy program named BPFd that receives commands and performs them on behalf
of whoever is requesting them. All the heavily lifting (compilation, parsing of user input, parsing of the hash maps,
presentation of results etc) is done by BCC tools on the host machine, with BPFd running on the target and being the
interface to the target kernel. BPFd encapsulates all the needs of BCC and performs them - this includes loading a BPF
program, creating, deleting and looking up maps, attaching a eBPF program to a kprobe, polling for new data that the
eBPF program may have written into a perf buffer, etc. If it&rsquo;s woken up because the perf buffer contains new data, it&rsquo;ll
inform BCC tools on the host about it, or it can return map data whenever requested, which may contain information
updated by the target eBPF program.</p>
<h3 id="simple-design">Simple design</h3>
<p>Before this work, the BCC tools architecture was as follows:
<img src="images/bcc-arch.png" alt="BCC architecture"></p>
<p>BPFd based invocations partition this, thus making it possible to do cross-development and execution of the tools across
machine and architecture boundaries. For instance, kernel sources that the BCC tools depend on can be on a development
machine, with eBPF code being loaded onto a remote machine. This partioning is illustrated in the following diagram:
<img src="images/bcc-with-bpfd-arch.png" alt="BCC architecture with BPFd"></p>
<p>The design of BPFd is quite simple, it expects commands on <code>stdin</code> (standard input) and provides the results over
<code>stdout</code> (standard output). Every command a single line always, no matter how big the command is. This allows easy
testing using <code>cat</code>, since one could simply <code>cat</code> a file with commands, and check if BPFd&rsquo;s <code>stdout</code> contain the
expected results. Results from a command, however can be multiple lines.</p>
<p>BPF maps are data structures that a BPF program uses to store data which can be
retrieved at a later time. Maps are represented by file descriptor returned by
the <code>bpf</code> system call once the map has been successfully created.
For example, following is a command to BPFd for creating a BPF hashtable map.</p>
<pre tabindex="0"><code>BPF_CREATE_MAP 1 count 8 40 10240 0
</code></pre><p>And the result from BPFd is:</p>
<pre tabindex="0"><code>bpf_create_map: ret=3
</code></pre><p>Since BPFd is proxying the map creation, the file descriptor (3 in this example) is
mapped into <code>BPFd's</code> file descriptor table. The file descriptor can be used later to
look up entries that the BPF program in the kernel may have created, or to clear all
entries in the map, as is done by tools that periodically clear the accounting done
by a BPF program.</p>
<p>The <code>BPF_CREATE_MAP</code> command in this example tells BPFd to create a map named
<code>count</code> with map type 1 (<a href="https://github.com/torvalds/linux/blob/master/include/uapi/linux/bpf.h#L101">type 1 is a hashtable
map</a>),
with a key size of 8 bytes and a value size of 40, maximum of 10240 entries and
no special flags. BPFd created a map and identified by file descriptor 3.</p>
<p>With the simple standard input/output design, it&rsquo;s possible to write wrappers around BPFd to handle more advanced
communication methods such as USB or Networking. As a part of my analysis work in the Android kernel team, I am
communicating these commands over the <a href="https://developer.android.com/studio/command-line/adb.html">Android Debug Bridge</a>
which interfaces with the target device over either USB or TCP/IP. I have shared several demos below.</p>
<h3 id="changes-to-the-bcc-project-for-working-with-bpfd">Changes to the BCC project for working with BPFd</h3>
<p><a href="https://github.com/iovisor/bcc/">BCC</a> needed several changes to be able to talk
to BPFd over a remote connection. All these changes <a href="https://github.com/joelagnel/bcc/tree/bcc-bpfd">are available
here</a> and will be pushed
upstream soon.</p>
<p>Following are all the BCC modifications that have been made:</p>
<h4 id="support-for-remote-communication-with-bpfd-such-as-over-the-network">Support for remote communication with BPFd such as over the network</h4>
<p>A new <code>remotes</code> module has been added to BCC tools with an abstraction that
different remote types, such as networking or USB must implement. This keeps
code duplication to a minimum. By implementing <a href="https://github.com/joelagnel/bcc/blob/bcc-bpfd/src/python/bcc/remote/base.py">the functions
needed</a>
for a remote, a new communication method can be easily added. Currently an
<code>adb</code> remote and a <code>process</code> remote are provided. The <code>adb</code> remote is for
communication with the target device over USB or TCP/IP using the <a href="https://developer.android.com/studio/command-line/adb.html">Android
Debug Bridge</a>. The
<code>process</code> remote is probably useful just for local testing. With the <code>process</code> remote,
BPFd is forked on the same machine running BCC and communicates with it over
<code>stdin</code> and <code>stdout</code>.</p>
<h4 id="changes-to-bcc-to-send-commands-to-the-remote-bpfd">Changes to BCC to send commands to the remote BPFd</h4>
<p><a href="https://github.com/iovisor/bcc/blob/master/src/cc/libbpf.c">libbpf.c</a> is the
main C file in the BCC project that talks to the kernel for all things BPF.
This is illustrated in the diagram above. Inorder to make BCC perform BPF
operations on the remote machine instead of the local machine, parts of BCC
that make calls to the local <code>libbpf.c</code> are now instead channeled to the remote
BPFd on the target. BPFd on the target then perform the commands on behalf of
BCC running locally, by calling into its copy of <code>libbpf.c</code>.</p>
<p>One of the tricky parts to making this work is, not only calls to <code>libbpf.c</code>
but certain other paths need to be channeled to the remote machine. For example, to
attach to a tracepoint, BCC needs a list of all available tracepoints on the
system. This list has to be obtained on the remote system, not the local one and is
the exact reason why there exists the <a href="https://github.com/joelagnel/bpfd/blob/master/src/bpfd.c#L421">GET_TRACE_EVENTS</a>
command in BPFd.</p>
<h4 id="making-the-kernel-build-for-correct-target-processor-architecture">Making the kernel build for correct target processor architecture</h4>
<p>When BCC compiles the C program encapsulated in a BCC tool into eBPF
instructions, it assumes that the eBPF program will run on the same processor
architecture that BCC is running on. This is incorrect especially when building
the eBPF program for a different target.</p>
<p>Some time ago, before I started this project, I <a href="https://patchwork.kernel.org/patch/9961801/">changed
this</a> when building the in-kernel
eBPF samples (which are simple standalone samples and unrelated to BCC). Now, I have had to <a href="https://github.com/joelagnel/bcc/commit/2a2f9d41c336d8aa058338ae536bd93d31dbb1ef">make a similar
change</a>
to BCC so that it compiles the C program correctly for the target architecture.</p>
<h3 id="installation">Installation</h3>
<p>Try it out for yourself! Follow the <a href="https://github.com/joelagnel/bpfd/blob/master/INSTALL.md#diy">Detailed</a> or
<a href="https://github.com/joelagnel/bpfd/blob/master/INSTALL.md">Simple</a> instructions. Also, apply this <a href="https://raw.githubusercontent.com/joelagnel/bpfd/master/patches/kernel/0001-bpf-stackmap-Implement-bpf_get_next_key.patch">kernel
patch</a>
to make it faster to run tools like offcputime. I am submitting this patch to LKML as we speak.</p>
<h3 id="bpf-demos-examples-of-bcc-tools-running-on-android">BPF Demos: examples of BCC tools running on Android</h3>
<h4 id="running-filetop">Running filetop</h4>
<p><code>filetop</code> is a BCC tool which shows you all read/write I/O operations with a similar experience to the <code>top</code> tool.
It refreshes every few seconds, giving you a live view of these operations.
Goto your bcc directory and set the environment variables needed. For Android running on Hikey960, I run:</p>
<pre tabindex="0"><code>joel@ubuntu:~/bcc# source arm64-adb.rc
</code></pre><p>which basically sets the following environment variables:</p>
<pre tabindex="0"><code>  export ARCH=arm64
  export BCC_KERNEL_SOURCE=/home/joel/sdb/hikey-kernel/
  export BCC_REMOTE=adb
</code></pre><p>You could also use the convenient bcc-set script provided in BPFd sources to set these environment variables for you.
Check <a href="https://github.com/joelagnel/bpfd/blob/master/INSTALL.md">INSTALL.md</a> file in BPFd sources for more information.</p>
<p>Next I start <code>filetop</code>:</p>
<pre tabindex="0"><code>joel@ubuntu:~/bcc# ./tools/filetop.py 5
</code></pre><p>This tells the tool to monitor file I/O every 5 seconds.</p>
<p>While <code>filetop</code> is running, I start the stock email app in Android and the output looks like:</p>
<pre tabindex="0"><code>  Tracing... Output every 5 secs. Hit Ctrl-C to end
  13:29:25 loadavg: 0.33 0.23 0.15 2/446 2931
 
  TID    COMM             READS  WRITES R_Kb    W_Kb    T FILE
  3787   Binder:2985_8    44     0      140     0       R profile.db
  3792   m.android.email  89     0      130     0       R Email.apk
  3813   AsyncTask #3     29     0      48      0       R EmailProvider.db
  3808   SharedPreferenc  1      0      16      0       R AndroidMail.Main.xml
  3792   m.android.email  2      0      16      0       R deviceName
  3815   SharedPreferenc  1      0      16      0       R MailAppProvider.xml
  3813   AsyncTask #3     8      0      12      0       R EmailProviderBody.db
  2434   WifiService      4      0      4       0       R iface_stat_fmt
  3792   m.android.email  66     0      2       0       R framework-res.apk
</code></pre><p>Notice the Email.apk being read by Android to load the email application, and then various other reads happening related
to the email app. Finally, WifiService continously reads iface_state_fmt to get network statistics for Android
accounting.</p>
<h4 id="running-biosnoop">Running biosnoop</h4>
<p>Biosnoop is another great tool shows you block level I/O operations (bio) happening on the system along with the latency
and size of the operation. Following is a sample output of running <code>tools/biosnoop.py</code> while doing random things in the
Android system.</p>
<pre tabindex="0"><code>  TIME(s)        COMM           PID    DISK    T  SECTOR    BYTES   LAT(ms)
  0.000000000    jbd2/sdd13-8   2135   sdd     W  37414248  28672      1.90
  0.001563000    jbd2/sdd13-8   2135   sdd     W  37414304  4096       0.43
  0.003715000    jbd2/sdd13-8   2135   sdd     R  20648736  4096       1.94
  5.119298000    kworker/u16:1  3848   sdd     W  11968512  8192       1.72
  5.119421000    kworker/u16:1  3848   sdd     W  20357128  4096       1.80
  5.448831000    SettingsProvid 2415   sdd     W  20648752  8192       1.70
</code></pre><h4 id="running-hardirq">Running hardirq</h4>
<p>This tool measures the total time taken by different hardirqs in the systems. Excessive time spent in hardirq can result
in poor real-time performance of the system.</p>
<pre><code>joel@ubuntu:~/bcc# ./tools/hardirqs.py
</code></pre>
<p>Output:</p>
<pre tabindex="0"><code>  Tracing hard irq event time... Hit Ctrl-C to end.
  HARDIRQ                    TOTAL_usecs
  wl18xx                             232
  dw-mci                            1066
  e82c0000.mali                     8514
  kirin                             9977
  timer                            22384
</code></pre><h4 id="running-biotop">Running biotop</h4>
<p>Run biotop while launching the android Gallery app and doing random stuff:</p>
<pre tabindex="0"><code>joel@ubuntu:~/bcc# ./tools/biotop.py
</code></pre><p>Output:</p>
<pre tabindex="0"><code>PID    COMM             D MAJ MIN DISK       I/O  Kbytes  AVGms
4524   droid.gallery3d  R 8   48  ?           33    1744   0.51
2135   jbd2/sdd13-8     W 8   48  ?           15     356   0.32
4313   kworker/u16:4    W 8   48  ?           26     232   1.61
4529   Jit thread pool  R 8   48  ?            4     184   0.27
2135   jbd2/sdd13-8     R 8   48  ?            7      68   2.19
2459   LazyTaskWriterT  W 8   48  ?            3      12   1.77
</code></pre><h3 id="open-issues-as-of-this-writing">Open issues as of this writing</h3>
<p>While most issues have been fixed, a few remain. Please check the <a href="https://github.com/joelagnel/bpfd/issues">issue
tracker</a> and contribute patches or help by testing.</p>
<h3 id="other-usecases-for-bpfd">Other usecases for BPFd</h3>
<p>While the main usecase at the moment is easier use of BCC tools on cross-development models, another potential usecase
that&rsquo;s gaining interest is easy loading of a BPF program. The BPFd code can be stored on disk in base64 format and sent
to bpfd using something as simple as:</p>
<pre tabindex="0"><code>joel@ubuntu:~/bpfprogs# cat my_bpf_prog.base64 | bpfd
</code></pre><p>In the Android kernel team, we are also expermenting for certain usecases that need eBPF, with loading a program with a
forked BPFd instance, creating maps, and then pinning them for use at a later time once BPFd exits and then kill the
BPFd fork since its done. Creating a separate process (fork/exec of BPFd) and having it load the eBPF program for you
has the distinct advantage that the <a href="https://github.com/torvalds/linux/blob/master/samples/bpf/bpf_load.c#L546">runtime-fixing up map file
descriptors</a> isn&rsquo;t needed in the loaded eBPF machine
instructions. In other words, the eBPF program&rsquo;s instructions can be pre-determined and statically loaded. The reason
for this convience is BPFd starts with the same number of file descriptors each time before the first map is created.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Building code for instrumentation on a different machine than the one actually
running the debugging code is beneficial and BPFd makes this possible.
Alternately, one could also write tracing code in their own kernel module on a
development machine, copy it over to a remote target, and do similar
tracing/debugging.  However, this is quite unsafe since kernel modules can
crash the kernel. On the other hand, eBPF programs are verified before they&rsquo;re
run and are guaranteed to be safe when loaded into the kernel, unlike kernel
modules.  Furthermore, the BCC project offers great support for parsing the
output of maps, processing them and presenting results all using the friendly
Python programming language. BCC tools are quite promising and could be the
future for easier and safer deep tracing endeavours. BPFd can hopefully make it
even more easier to run these tools for folks such as Embedded system and Android
developers who typically compile their kernels on their local machine and run
them on a non-local target machine.</p>
<p>If you have any questions, feel to <a href="http://www.linuxinternals.org/joel/">reach out</a> to me or drop me a note in the
comments section.</p>
</div>

    </article>

    <article>
Most Recent Post:
      
  <header>
    
      <h1 class="entry-title">C&#43;&#43; rvalue references</h1>
    
    
      <p class="meta">
        
        
           | <a href="http://localhost:1313/blog/1/01/01/c-rvalue-references/#disqus_thread"
             data-disqus-identifier="http://localhost:1313/blog/1/01/01/c-rvalue-references/">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>The author works in the ChromeOS kernel team, where most of the system
libraries, low-level components and user space is written in C++. Thus the
writer has no choice but to be familiar with C++. It is not that hard, but some
things are confusing. rvalue references are definitely confusing.</p>
<p>In this post, I wish to document rvalue references by simple examples, before I forget it.</p>
<p>Refer to <a href="https://www.chromium.org/rvalue-references">this article</a> for in-depth coverage on rvalue references.</p>
<p>In a nutshell: An rvalue reference can be used to construct a C++ object
efficiently using a &ldquo;move constructor&rdquo;. This efficiency is achieved by the
object&rsquo;s move constructor by <em>moving</em> the underlying memory of the object
efficiently to the destination instead of a full copy. Typically the move
constructor of the object will copy pointers within the source object into the
destination object, and null the pointer within the source object.</p>
<p>An rvalue reference is denoted by a double ampersand (&amp;&amp;) when you want to
create an rvalue reference as a variable.</p>
<p>For example <code>T &amp;&amp;y;</code> defines a variable y which holds an rvalue reference of
type T. I have almost never seen an rvalue reference variable created this way
in real code. I also have no idea when it can be useful. Almost always they are
created by either of the 2 methods in the next section. These methods create an
&ldquo;unnamed&rdquo; rvalue reference which can be passed to a class&rsquo;s move constructor.</p>
<h2 id="when-is-an-rvalue-reference-created">When is an rvalue reference created?</h2>
<p>In the below example, we create an rvalue reference to a vector, and create
another vector object from this.</p>
<p>This can happen in 2 ways (that I know off):</p>
<h3 id="1-using-stdmove">1. Using std::move</h3>
<p>This converts an lvalue reference to an rvalue reference.</p>
<p>Example:</p>
<pre tabindex="0"><code>#include &lt;iostream&gt;
#include &lt;vector&gt;

int main()
{
    int *px, *py;
    std::vector&lt;int&gt; x = {4,3};
    px = &amp;(x[0]);
 
    // Convert lvalue &#39;x&#39; to rvalue reference and pass
    // it to vector&#39;s overloaded move constructor.
    std::vector&lt;int&gt; y(std::move(x)); 
    py = &amp;(y[0]);

    // Confirm the new vector uses same storage
    printf(&#34;same vector? : %d\n&#34;, px == py); // prints 1
}
</code></pre><h3 id="2-when-returning-something-from-a-function">2. When returning something from a function</h3>
<p>The returned object from the function can be caught as an rvalue reference to that object.</p>
<pre tabindex="0"><code>#include &lt;iostream&gt;
#include &lt;vector&gt;

int *pret;
int *py;

std::vector&lt;int&gt; myf(int a)
{
    vector&lt;int&gt; ret;

    ret.push_back(a * a);

    pret = &amp;(ret[0]);

    // Return is caught as an rvalue ref: vector&lt;int&gt; &amp;&amp;
    return ret;
}

int main()
{
    // Invoke vector&#39;s move constructor.
    std::vector&lt;int&gt; y(myf(4)); 
    py = &amp;(y[0]);

    // Confirm the vectors share the same underlying storage
    printf(&#34;same vector? : %d\n&#34;, pret == py); // prints 1
}
</code></pre><h3 id="note-on-move-asssignment">Note on move asssignment</h3>
<p><a href="https://stackoverflow.com/questions/4986673/c11-rvalues-and-move-semantics-confusion-return-statement">Interestingly</a>,
if you construct vector &lsquo;y&rsquo; using the assignment operator: <code>std::vector&lt;int&gt; y = myf(4);</code>, the compiler may decide to use the move constructor automatically
even though assignment is chosen. I believe this is because of vector&rsquo;s <a href="https://en.cppreference.com/w/cpp/language/move_assignment">move
assignment operator
overload</a>.</p>
<p>Further, the compiler may even not invoke a constructor at all and just perform
RVO (Return Value Optimization).</p>
<h2 id="quiz">Quiz</h2>
<h4 id="question">Question:</h4>
<p>If I create a named rvalue reference using std::move and then use this to
create a vector, the underlying storage of the new vector is different. Why?</p>
<pre tabindex="0"><code>#include &lt;iostream&gt;
#include &lt;vector&gt;

int *pret;
int *py;

std::vector&lt;int&gt; myf(int a)
{
    vector&lt;int&gt; ret;

    ret.push_back(a * a);

    pret = &amp;(ret[0]);

    // Return is caught as an rvalue ref: vector&lt;int&gt; &amp;&amp;
    return ret;
}

int main()
{
    // Invoke vector&#39;s move constructor.
    std::vector&lt;int&gt;&amp;&amp; ref = myf(4);
    std::vector&lt;int&gt; y(ref); 
    py = &amp;(y[0]);

    // Confirm the vectors share the same underlying storage
    printf(&#34;same vector? : %d\n&#34;, pret == py); // prints 0
}
</code></pre><h4 id="answer">Answer</h4>
<p>The answer is: because the value category of the id-expression &lsquo;ref&rsquo; is lvalue,
the copy constructor will be chosen. To use the move constructor, it has to be
<code>std::vector&lt;int&gt; y(std::move(ref));</code>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>rvalue references are confusing and sometimes the compiler can do different
optimizations to cause further confusion. It is best to follow well known
design patterns when designing your code. It may be best to also try to avoid
rvalue references altogether but hopefully this article helps you understand it
a bit more when you come across large C++ code bases.</p>
</div>

    </article>

    <article>
Most Recent Post:
      
  <header>
    
      <h1 class="entry-title">Categories</h1>
    
    
      <p class="meta">
        
        
           | <a href="http://localhost:1313/categories/#disqus_thread"
             data-disqus-identifier="http://localhost:1313/categories/">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"></div>

    </article>

    <article>
Most Recent Post:
      
  <header>
    
      <h1 class="entry-title">false</h1>
    
    
      <p class="meta">
        
        
      </p>
    
  </header>


<div class="entry-content"><p>Hi! I&rsquo;m Joel and I run this site! I&rsquo;m a Linux kernel developer and work at Google. My interests are scheduler, tracing, synchronization and kernel internals.</p>
<p>Follow me on <a href="https://twitter.com/joel_linux">Twitter</a>, <a href="https://plus.google.com/102415785508850230338">Google+</a> and <a href="https://www.linkedin.com/in/joelagnel">LinkedIn</a>. Email me at: <a href="mailto:joel@linuxinternals.org">joel@linuxinternals.org</a></p>
<p><a href="https://patchwork.kernel.org/project/LKML/list/?submitter=170577">Here&rsquo;s a list</a> of recent kernel patches I submitted. I got <a href="http://hackaday.com/2014/06/08/the-in-circuit-sd-card-switch/">featured on hackaday</a> and <a href="https://lwn.net/Articles/744522/">have written for LWN</a> as well. <a href="/joel/joel-resume.pdf">Check out my resume</a> and also see a list of past <a href="/resources">talks and presentations</a>.</p>
<p><strong><a href="/linuxinternals/">LinuxInternals.org</a></strong> is a resource I created as a collection of articles and resources exploring Linux kernel and internals topics.</p>
<p>Here&rsquo;s a list the full list of all articles I ever wrote:
{{ range site.RegularPages }}</p>
 <li><span>{{ .Date.Format "02 Jan 2006" }}</span> &nbsp; <a href="{{ .Permalink }}">{{ .Title }}</a> 
 {{ with .Params.categories }}
 [{{ if reflect.IsSlice . }}{{ range $index, $category := . }}<a href="{{ "/categories/" | relURL }}#{{ $category | urlize }}">{{ $category }}</a>{{ if ne $index (sub (len .) 1) }}, {{ end }}{{ end }}{{ else }}{{ $categories := split . ", " }}{{ range $index, $category := $categories }}<a href="{{ "/categories/" | relURL }}#{{ $category | urlize }}">{{ $category }}</a>{{ if ne $index (sub (len $categories) 1) }}, {{ end }}{{ end }}{{ end }}]
 {{ end }}
 </li>
{{ end }}</div>

    </article>

    <article>
Most Recent Post:
      
  <header>
    
      <h1 class="entry-title">Figuring out herd7 memory models</h1>
    
    
      <p class="meta">
        
        
           | <a href="http://localhost:1313/blog/1/01/01/figuring-out-herd7-memory-models/#disqus_thread"
             data-disqus-identifier="http://localhost:1313/blog/1/01/01/figuring-out-herd7-memory-models/">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p><a href="/resources/lkmm_herd7.pdf">This article has been published as a PDF, download here.</a></p>
</div>

    </article>

    <article>
Most Recent Post:
      
  <header>
    
      <h1 class="entry-title">Getting YouCompleteMe working for kernel development</h1>
    
    
      <p class="meta">
        
        
           | <a href="http://localhost:1313/blog/1/01/01/getting-youcompleteme-working-for-kernel-development/#disqus_thread"
             data-disqus-identifier="http://localhost:1313/blog/1/01/01/getting-youcompleteme-working-for-kernel-development/">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p><a href="https://github.com/Valloric/YouCompleteMe">YCM</a> is a pretty neat tool for
speedy kernel development in vim. Especially when you don&rsquo;t want to write a
whole bunch of code, and then deal with 100s of compiler errors. It is better
to fix the errors on the spot, as you write the code.  That&rsquo;s exactly what YCM
is best at since it constantly builds the code on the fly. The other great
thing about it among other things being, it will show you function prototypes
and so forth as you type, so you can call functions correctly with the right
set of parameters and types. YCM uses <a href="https://clangd.llvm.org/">clangd</a> under
the hood which understands code navigation, helps with code completion, and so
forth. <code>clangd</code> is used by a whole plehtora of IDEs and tools. I remember using
it when I tried to get <code>vscode</code> working with ChromeOS source navigation (which
is actually a bigger project in terms of lines of code, than the Linux
kernel!).</p>
<p>Interestingly YCM does not use <code>cscope</code> even if it is available, and they do
not want to support it. Further, they reluctantly support <code>ctags</code>. Since I
don&rsquo;t use <code>ctags</code>, I am not sure how having tags available changes YCM
behavior and how it works with <code>clangd</code>. But that is something worth trying.</p>
<p>Getting YCM working with vim is pretty easy, but requires a few steps.</p>
<p>First you have to build a <code>compile_commands.json</code> file in the kernel root. To
do so, run:</p>
<pre tabindex="0"><code>bear -- make -j99 CC=clang
</code></pre><p>Note the <code>CC</code> variable passed to Make. It has to be <code>clang</code>, otherwise YCM
throws a tonne of errors when it is in use. I believe that is because clangd
incorrectly passes gcc-specific options to clang, which are not all supported.</p>
<p>Following
<a href="https://stackoverflow.com/questions/30180064/how-to-setup-youcompleteme-for-kernel-and-device-driver-development">this</a>
stackoverflow post shows how to avoid some issues. This post is how I learnt to
use <code>bear</code>. Just use <code>bear</code> and ignore all other posts or articles that ask you
to create a <code>.ycm_extra_conf.py</code> file. I did not need to do that at all.</p>
<p>I faced the following issues:</p>
<ol>
<li>
<p>First, there might some warnings in the code that arise when clangd/clang
try to build your code on the fly. In case these warnings are not legit, it is
best to ignore them. For that the <code>g:ycm_filter_diagnostics</code> vim variable can
be defined.  The above post shows an example.</p>
</li>
<li>
<p>Editing header files may not work well: This happens because header files
cannot really be &ldquo;built&rdquo;. Further, sometimes header files require other header
files to be included, which may be done in the actual C file that includes the
header but not the header itself. However, vim/YCM does not know about that.
This issue can simply be fixed by including other header dependencies into the
header file being edited.</p>
</li>
<li>
<p>Kernel config macro dependencies: If a build has not happened yet, or you are
writing C code that depends on a new CONFIG option, a build may not have
happened yet, so the <code>autoconf</code> headers may not yet be available. This causes
YCM to not build those sections of code. A quick fix might be to add something
like this in the sources:</p>
</li>
</ol>
<pre tabindex="0"><code>#ifndef CONFIG_FOO_BAR
#define CONFIG_FOO_BAR
#endif
</code></pre><p>Similar tricks can be employed to satisfy macros such as <code>IS_ENABLED(CONFIG_FOO_BAR)</code>.</p>
<p>Hope this helps, do you have any other tips or ideas to use YCM better? If so,
let me know in the comments!</p>
</div>

    </article>

    <article>
Most Recent Post:
      
  <header>
    
      <h1 class="entry-title">GUS (Global Unbounded Sequences)</h1>
    
    
      <p class="meta">
        
        
           | <a href="http://localhost:1313/blog/1/01/01/gus-global-unbounded-sequences/#disqus_thread"
             data-disqus-identifier="http://localhost:1313/blog/1/01/01/gus-global-unbounded-sequences/">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>GUS is a memory reclaim algorithm used in FreeBSD, similar to RCU. It is
borrows concepts from Epoch and Parsec. A video of a presentation describing
the integration of GUS with UMA (FreeBSD&rsquo;s slab implementation) is here:
<a href="https://www.youtube.com/watch?v=ZXUIFj4nRjk">https://www.youtube.com/watch?v=ZXUIFj4nRjk</a></p>
<p>The best description of GUS is in the FreeBSD code
<a href="http://bxr.su/FreeBSD/sys/kern/subr_smr.c#44">itself</a>. It is based on the
concept of global write clock, with readers catching up to writers.</p>
<p>Effectively, I see GUS as an implementation of light traveling from distant
stars. When a photon leaves a star, it is no longer needed by the star and is
ready to be reclaimed. However, on earth we can&rsquo;t see the photon yet, we can
only see what we&rsquo;ve been shown so far, and in a way, if we&rsquo;ve not seen
something because enough &ldquo;time&rdquo; has not passed, then we may not reclaim it yet.
If we&rsquo;ve not seen something, we will see it at some point in the future. Till
then we need to sit tight.</p>
<p>Roughly, an implementation has 2+N counters (with N CPUs):</p>
<ol>
<li>Global write sequence.</li>
<li>Global read sequence.</li>
<li>Per-cpu read sequence (read from #1 when a reader starts)</li>
</ol>
<p>On freeing, the object is tagged with the write sequence. Only once global read
sequence has caught up with global write sequence, the object is freed. Until
then, the free&rsquo;ing is deferred. The <code>poll()</code> operation updates #2 by referring
to #3 of all CPUs.  Whatever was tagged between the old read sequence and new
read sequence can be freed. This is similar to <code>synchronize_rcu()</code> in the Linux
kernel which waits for all readers to have finished observing the object being
reclaimed.</p>
<p>Note the scalability drawbacks of this reclaim scheme:</p>
<ol>
<li>
<p>Expensive poll operation if you have 1000s of CPUs.  (Note: Parsec uses a
tree-based mechanism to improve the situation which GUS could consider)</p>
</li>
<li>
<p>Heavy-weight memory barriers are needed (SRCU has a similar drawback) to
ensure ordering properties of reader sections with respect to poll() operation.</p>
</li>
<li>
<p>There can be a delay between reading the global write-sequence number and
writing it into the per-cpu read-sequence number. This can cause the per-cpu
read-sequence to advance past the global write-sequence. Special handling is
needed.</p>
</li>
</ol>
<p>One advantage of the scheme could be implementation simplicity.</p>
<p>RCU (not SRCU or Userspace RCU) doesn&rsquo;t suffer from these drawbacks.
Reader-sections in Linux kernel RCU are extremely scalable and lightweight.</p>
</div>

    </article>

    <article>
Most Recent Post:
      
  <header>
    
      <h1 class="entry-title">List of articles</h1>
    
    
      <p class="meta">
        
        
           | <a href="http://localhost:1313/blog/archives/#disqus_thread"
             data-disqus-identifier="http://localhost:1313/blog/archives/">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"></div>

    </article>



<div class="pagination">
  
    <a href="/">&laquo; Previous Post</a> &nbsp; &nbsp; &nbsp;
  

  
    <a href="/page/3/">Next Post&raquo;</a>
  
</div>



</div>


<aside class="sidebar">
  <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="http://localhost:1313/blog/2023/06/25/svm-and-vectors-for-the-curious/">SVM and vectors for the curious</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/2018/12/22/dumping-user-and-kernel-stacks-on-kernel-events/">Dumping User and Kernel stacks on Kernel events</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/2018/02/10/usdt-for-reliable-userspace-event-tracing/">USDT for reliable Userspace event tracing</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/2016/12/31/armv8-flamegraph-and-nmi-support/">ARMv8: flamegraph and NMI support</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/2016/06/18/ftrace-events-mechanism/">Ftrace events mechanism</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/2016/03/20/tif_need_resched-why-is-it-needed/">TIF_NEED_RESCHED: why is it needed</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/2015/12/25/tying-2-voltage-sources/signals-together/">Tying 2 voltage sources/signals together</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/2014/06/04/microsd-card-remote-switch/">MicroSD card remote switch</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/2014/05/07/linux-spinlock-internals/">Linux Spinlock Internals</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/2014/04/24/studying-cache-line-sharing-effects-on-smp-systems/">Studying cache-line sharing effects on SMP systems</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/2014/04/22/design-of-fork-followed-by-exec-in-linux/">Design of fork followed by exec in Linux</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/"></a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/bpfd-running-bcc-tools-remotely-across-systems/">BPFd- Running BCC tools remotely across systems</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/c-rvalue-references/">C&#43;&#43; rvalue references</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/categories/">Categories</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/joel/">false</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/figuring-out-herd7-memory-models/">Figuring out herd7 memory models</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/getting-youcompleteme-working-for-kernel-development/">Getting YouCompleteMe working for kernel development</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/gus-global-unbounded-sequences/">GUS (Global Unbounded Sequences)</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/archives/">List of articles</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/making-sense-of-scheduler-deadlocks-in-rcu/">Making sense of scheduler deadlocks in RCU</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/modeling-lack-of-store-ordering-using-pluscal-and-a-wishlist/">Modeling (lack of) store ordering using PlusCal - and a wishlist</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/on-workings-of-hrtimers-slack-time-functionality/">On workings of hrtimer&#39;s slack time functionality</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/powerpc-stack-guard-false-positives-in-linux-kernel/">PowerPC stack guard false positives in Linux kernel</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/rcu-and-dynticks-idle-mode/">RCU and dynticks-idle mode</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/rcu-preempt-what-happens-on-a-context-switch/">RCU-preempt: What happens on a context switch</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/resources/">Resources</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/selinux-debugging-on-chromeos/">SELinux Debugging on ChromeOS</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/single-stepping-the-kernels-c-code/">Single-stepping the kernel&#39;s C code</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/srcu-state-double-scan/">SRCU state double scan</a>
      </li>
    
      <li class="post">
        <a href="http://localhost:1313/blog/1/01/01/understanding-hazard-pointers/">Understanding Hazard Pointers</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>About Me</h1>
  <p>A little something about me.</p>
</section>
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2025 - Joel Fernandes -
  <span class="credit">Powered by <a href="https://gohugo.io">Hugo</a></span>
</p></footer>
  
</body>
</html>