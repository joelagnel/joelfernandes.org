<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Synchronization on JoelFernandes.org</title>
    <link>http://localhost:1313/categories/synchronization/</link>
    <description>Recent content in Synchronization on JoelFernandes.org</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Apr 2014 20:28:24 -0500</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/synchronization/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Studying cache-line sharing effects on SMP systems</title>
      <link>http://localhost:1313/blog/2014/04/24/studying-cache-line-sharing-effects-on-smp-systems/</link>
      <pubDate>Thu, 24 Apr 2014 20:28:24 -0500</pubDate>
      <guid>http://localhost:1313/blog/2014/04/24/studying-cache-line-sharing-effects-on-smp-systems/</guid>
      <description>Having read the chapter on counting and per-CPU counters in Paul Mckenney&amp;rsquo;s recent book, I thought I would do a small experiment to check how good or bad it would be if those per-CPU counters were close to each other in memory.&#xA;Paul talks about using one global shared counter for N threads on N CPUs, and the effects it can have on the cache. Each CPU core&amp;rsquo;s cache in an SMP system will need exclusive rights on a specific cache line of memory, before it can do the write.</description>
    </item>
    <item>
      <title>SRCU state double scan</title>
      <link>http://localhost:1313/blog/1/01/01/srcu-state-double-scan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/srcu-state-double-scan/</guid>
      <description>The SRCU flavor of RCU uses per-cpu counters to detect that every CPU has passed through a quiescent state for a particular SRCU lock instance (srcu_struct).&#xA;There&amp;rsquo;s are total of 4 counters per-cpu. One pair for locks, and another for unlocks. You can think of the SRCU instance to be split into 2 parts. The readers sample srcu_idx and decided which part to use. Each part corresponds to one pair of lock and unlock counters.</description>
    </item>
    <item>
      <title>Understanding Hazard Pointers</title>
      <link>http://localhost:1313/blog/1/01/01/understanding-hazard-pointers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/1/01/01/understanding-hazard-pointers/</guid>
      <description>Introduction In concurrent systems, managing shared resources efficiently and safely is of paramount importance. Hazard pointers are a powerful synchronization mechanism that can be used to address this issue. In this post, we will explore how hazard pointers work, provide a simple example to illustrate their usage, and compare them with RCU (Read-Copy-Update). Additionally, we will dive into the implementation details of hazard pointers, including the per-CPU and per-thread data structures used to maintain them.</description>
    </item>
  </channel>
</rss>
